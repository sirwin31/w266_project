{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaulate Distilbert TopicChooser Model\n",
    "### 25 Nov 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Evaluation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Evaulation Parameters\n",
    "MODEL_NAME = \"roberta-base\"\n",
    "MODEL_FILE =\"saved_model_epoch10_20201129_0424.tar\"\n",
    "VAL_DATASET = \"val_data_28Nov_roberta_pf.pickle\"\n",
    "EVAL_BATCH_SIZE = 16\n",
    "DESCRIPTION = \"PolitiFact only model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Setup and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn.metrics\n",
    "import tqdm\n",
    "import torch\n",
    "import transformers as hft\n",
    "\n",
    "sys.path.insert(0, \"/home/jupyter\")\n",
    "import util.log\n",
    "import util.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation data\n",
    "with open(VAL_DATASET, \"rb\") as vfile:\n",
    "    val_dataset = pickle.load(vfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved model\n",
    "checkpoint = torch.load(MODEL_FILE)\n",
    "model = (hft.RobertaForSequenceClassification\n",
    "         .from_pretrained(MODEL_NAME))\n",
    "model.load_state_dict(checkpoint[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "model.to(device)\n",
    "model.eval();\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Evaluation Loop and Results Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaulate model\n",
    "eval_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                batch_size=EVAL_BATCH_SIZE,\n",
    "                                shuffle=False)\n",
    "labels = []\n",
    "preds = []\n",
    "logits = []\n",
    "probs = []\n",
    "sources = []\n",
    "article_tokens = []\n",
    "file_names = []\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for art_num, article in tqdm.tqdm(enumerate(eval_loader)):\n",
    "        input_ids = article[\"input_ids\"].to(device)\n",
    "        attent_mask = article[\"attention_mask\"].to(device)\n",
    "        output = model(input_ids,\n",
    "                       attention_mask=attent_mask,\n",
    "                       output_hidden_states=False,\n",
    "                       output_attentions=False)\n",
    "        prob = softmax(output[0].detach().cpu()).numpy()\n",
    "        logit = output[0].detach().cpu().numpy()\n",
    "        pred = [0 if lgt[0] > lgt[1] else 1 for lgt in logit]\n",
    "        label = article[\"labels\"].numpy()\n",
    "        labels.extend(label)\n",
    "        preds.extend(pred)\n",
    "        logits.extend(logit)\n",
    "        probs.extend(prob)\n",
    "        article_tokens.extend(article[\"article_tokens\"].numpy())\n",
    "        sources.extend(article[\"sources\"])\n",
    "        file_names.extend(article[\"file_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Source</th>\n",
       "      <th>Token_Length</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Logit_real(0)</th>\n",
       "      <th>Logit_fake(1)</th>\n",
       "      <th>Prob_real(0)</th>\n",
       "      <th>Prob_real(1)</th>\n",
       "      <th>File_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>politifact</td>\n",
       "      <td>10104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.232014</td>\n",
       "      <td>-4.277524</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>politifact304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>politifact</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.695490</td>\n",
       "      <td>4.622222</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>politifact13663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>politifact</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.474310</td>\n",
       "      <td>4.359578</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.999854</td>\n",
       "      <td>politifact13823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>politifact</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.668920</td>\n",
       "      <td>4.603256</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.999906</td>\n",
       "      <td>politifact14447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>politifact</td>\n",
       "      <td>481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.317299</td>\n",
       "      <td>1.872538</td>\n",
       "      <td>0.014923</td>\n",
       "      <td>0.985077</td>\n",
       "      <td>politifact2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>politifact</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.785406</td>\n",
       "      <td>3.608128</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>politifact13352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>131</td>\n",
       "      <td>politifact</td>\n",
       "      <td>793</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.607570</td>\n",
       "      <td>4.474548</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>politifact15241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>politifact</td>\n",
       "      <td>4956</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.005533</td>\n",
       "      <td>-4.207335</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>politifact51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>politifact</td>\n",
       "      <td>312</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.122876</td>\n",
       "      <td>3.760148</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.999623</td>\n",
       "      <td>politifact14888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>politifact</td>\n",
       "      <td>357</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.671828</td>\n",
       "      <td>4.558427</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>politifact14164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Article      Source  Token_Length  Predictions  Labels  Logit_real(0)  \\\n",
       "0          0  politifact         10104            0       0       4.232014   \n",
       "1          1  politifact           246            1       1      -4.695490   \n",
       "2          2  politifact           330            1       1      -4.474310   \n",
       "3          3  politifact           360            1       1      -4.668920   \n",
       "4          4  politifact           481            1       0      -2.317299   \n",
       "..       ...         ...           ...          ...     ...            ...   \n",
       "130      130  politifact           250            1       0      -3.785406   \n",
       "131      131  politifact           793            1       1      -4.607570   \n",
       "132      132  politifact          4956            0       0       4.005533   \n",
       "133      133  politifact           312            1       1      -4.122876   \n",
       "134      134  politifact           357            1       1      -4.671828   \n",
       "\n",
       "     Logit_fake(1)  Prob_real(0)  Prob_real(1)        File_Name  \n",
       "0        -4.277524      0.999798      0.000201    politifact304  \n",
       "1         4.622222      0.000090      0.999910  politifact13663  \n",
       "2         4.359578      0.000146      0.999854  politifact13823  \n",
       "3         4.603256      0.000094      0.999906  politifact14447  \n",
       "4         1.872538      0.014923      0.985077   politifact2258  \n",
       "..             ...           ...           ...              ...  \n",
       "130       3.608128      0.000615      0.999385  politifact13352  \n",
       "131       4.474548      0.000114      0.999886  politifact15241  \n",
       "132      -4.207335      0.999729      0.000271     politifact51  \n",
       "133       3.760148      0.000377      0.999623  politifact14888  \n",
       "134       4.558427      0.000098      0.999902  politifact14164  \n",
       "\n",
       "[135 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label of 0 is real, 1 is fake\n",
    "eval_results = pd.DataFrame({\"Article\": list(range(len(labels))),\n",
    "                             \"Source\": sources,\n",
    "                             \"Token_Length\": article_tokens,\n",
    "                             \"Predictions\": preds,\n",
    "                             \"Labels\": labels,\n",
    "                             \"Logit_real(0)\": [x[0] for x in logits],\n",
    "                             \"Logit_fake(1)\": [x[1] for x in logits],\n",
    "                             \"Prob_real(0)\": [x[0] for x in probs],\n",
    "                             \"Prob_real(1)\": [x[1] for x in probs],\n",
    "                             \"File_Name\": file_names})\n",
    "\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation data to csv file\n",
    "eval_results.to_csv(\"eval_data_\" + MODEL_FILE[12:-4] + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Overall Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'PolitiFact only model',\n",
       " 'eval_notes': 'Evaluating PolitiFact data',\n",
       " 'model': 'saved_model_epoch10_20201129_0424.tar',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 16,\n",
       " 'Date_evaluated': '28Nov2020',\n",
       " 'train_data': 'train_data_28Nov_roberta_pf.pickle',\n",
       " 'val_data': 'eval_data_epoch10_20201129_0424.csv',\n",
       " 'eval_data': 'val_data_28Nov_roberta_pf.pickle',\n",
       " 'accuracy': 0.9555555555555556,\n",
       " 'precision': 0.922077922077922,\n",
       " 'recall': 1.0,\n",
       " 'f1': 0.9594594594594594}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall metrics\n",
    "precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "    eval_results.Labels, eval_results.Predictions, average=\"binary\")\n",
    "accuracy = sklearn.metrics.accuracy_score(eval_results.Labels, eval_results.Predictions)\n",
    "\n",
    "metrics = {\"description\": DESCRIPTION,\n",
    "           \"eval_notes\": \"Evaluating PolitiFact data\",\n",
    "           \"model\": MODEL_FILE,\n",
    "           \"epochs\": checkpoint[\"epoch\"],\n",
    "           \"batch_size\": EVAL_BATCH_SIZE,\n",
    "           \"Date_evaluated\": \"28Nov2020\",\n",
    "           \"train_data\": \"train_data_28Nov_roberta_pf.pickle\",\n",
    "           \"val_data\": \"eval_data_\" + MODEL_FILE[12:-4] + \".csv\",\n",
    "           \"eval_data\": VAL_DATASET,\n",
    "           \"accuracy\": accuracy,\n",
    "           \"precision\": precision,\n",
    "           \"recall\": recall,\n",
    "           \"f1\": f1}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to JSON text file.\n",
    "with open(\"eval_metrics_\" + MODEL_FILE[12:-4] + \".json\", \"wt\") as jfile:\n",
    "    json.dump(metrics, jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gossip</th>\n",
       "      <th>political</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gossip</th>\n",
       "      <td>2050</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>135</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           gossip  political\n",
       "gossip       2050        616\n",
       "political     135        727"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = pd.DataFrame(sklearn.metrics.confusion_matrix(eval_results.Labels, eval_results.Predictions))\n",
    "label_titles = {0: \"gossip\", 1: \"political\"}\n",
    "cm.rename(index=label_titles, columns=label_titles, inplace=True)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
