{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaulate Distilbert Model\n",
    "### 25 Nov 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Evaluation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Evaulation Parameters\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MODEL_FILE =\"saved_model_epoch10_20201126_1415.tar\"\n",
    "VAL_DATASET = \"val_dataset_25Nov_gcpf_distilbert.pickle\"\n",
    "EVAL_BATCH_SIZE = 32\n",
    "DESCRIPTION = \"Distilbert trained on politifact and gossipcop training data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Setup and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn.metrics\n",
    "import tqdm\n",
    "import torch\n",
    "import transformers as hft\n",
    "\n",
    "sys.path.insert(0, \"/home/jupyter\")\n",
    "import util.log\n",
    "import util.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load evaluation data\n",
    "with open(VAL_DATASET, \"rb\") as vfile:\n",
    "    val_dataset = pickle.load(vfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved model\n",
    "checkpoint = torch.load(MODEL_FILE)\n",
    "model = (hft.DistilBertForSequenceClassification\n",
    "         .from_pretrained(MODEL_NAME))\n",
    "model.load_state_dict(checkpoint[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "model.to(device)\n",
    "model.eval();\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Evaluation Loop and Results Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "115it [00:31,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Evaulate model\n",
    "eval_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                batch_size=EVAL_BATCH_SIZE,\n",
    "                                shuffle=False)\n",
    "labels = []\n",
    "preds = []\n",
    "logits = []\n",
    "probs = []\n",
    "sources = []\n",
    "article_tokens = []\n",
    "file_names = []\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for art_num, article in tqdm.tqdm(enumerate(eval_loader)):\n",
    "        input_ids = article[\"input_ids\"].to(device)\n",
    "        attent_mask = article[\"attention_mask\"].to(device)\n",
    "        output = model(input_ids,\n",
    "                       attention_mask=attent_mask,\n",
    "                       output_hidden_states=False,\n",
    "                       output_attentions=False)\n",
    "        prob = softmax(output[0].detach().cpu()).numpy()\n",
    "        logit = output[0].detach().cpu().numpy()\n",
    "        pred = [0 if lgt[0] > lgt[1] else 1 for lgt in logit]\n",
    "        label = article[\"labels\"].numpy()\n",
    "        labels.extend(label)\n",
    "        preds.extend(pred)\n",
    "        logits.extend(logit)\n",
    "        probs.extend(prob)\n",
    "        article_tokens.extend(article[\"article_tokens\"].numpy())\n",
    "        sources.extend(article[\"sources\"])\n",
    "        file_names.extend(article[\"file_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Source</th>\n",
       "      <th>Token_Length</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Logit_real(0)</th>\n",
       "      <th>Logit_fake(1)</th>\n",
       "      <th>Prob_real(0)</th>\n",
       "      <th>Prob_real(1)</th>\n",
       "      <th>File_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gossipcop</td>\n",
       "      <td>1366</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.722003</td>\n",
       "      <td>-4.976188</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>gossipcop-848731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>gossipcop</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.600271</td>\n",
       "      <td>-3.713171</td>\n",
       "      <td>0.999334</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>gossipcop-944840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>gossipcop</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.897395</td>\n",
       "      <td>-4.097625</td>\n",
       "      <td>0.999663</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>gossipcop-1267637959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>gossipcop</td>\n",
       "      <td>1493</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.645965</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>0.238087</td>\n",
       "      <td>0.761913</td>\n",
       "      <td>gossipcop-909119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>gossipcop</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.753866</td>\n",
       "      <td>-5.004924</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>gossipcop-866623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>3658</td>\n",
       "      <td>gossipcop</td>\n",
       "      <td>670</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.558948</td>\n",
       "      <td>0.280135</td>\n",
       "      <td>0.301728</td>\n",
       "      <td>0.698272</td>\n",
       "      <td>gossipcop-6231788357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>3659</td>\n",
       "      <td>gossipcop</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.796472</td>\n",
       "      <td>-5.073880</td>\n",
       "      <td>0.999948</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>gossipcop-896655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>3660</td>\n",
       "      <td>gossipcop</td>\n",
       "      <td>10233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.745799</td>\n",
       "      <td>0.738307</td>\n",
       "      <td>0.184808</td>\n",
       "      <td>0.815192</td>\n",
       "      <td>gossipcop-856760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>3661</td>\n",
       "      <td>gossipcop</td>\n",
       "      <td>459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.764915</td>\n",
       "      <td>-5.085905</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>gossipcop-854426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>3662</td>\n",
       "      <td>gossipcop</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.256328</td>\n",
       "      <td>-4.499780</td>\n",
       "      <td>0.999843</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>gossipcop-7744016686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3663 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Article     Source  Token_Length  Predictions  Labels  Logit_real(0)  \\\n",
       "0           0  gossipcop          1366            0       0       4.722003   \n",
       "1           1  gossipcop           509            0       0       3.600271   \n",
       "2           2  gossipcop           298            0       1       3.897395   \n",
       "3           3  gossipcop          1493            1       0      -0.645965   \n",
       "4           4  gossipcop           151            0       0       4.753866   \n",
       "...       ...        ...           ...          ...     ...            ...   \n",
       "3658     3658  gossipcop           670            1       1      -0.558948   \n",
       "3659     3659  gossipcop           218            0       0       4.796472   \n",
       "3660     3660  gossipcop         10233            1       0      -0.745799   \n",
       "3661     3661  gossipcop           459            0       0       4.764915   \n",
       "3662     3662  gossipcop           228            0       1       4.256328   \n",
       "\n",
       "      Logit_fake(1)  Prob_real(0)  Prob_real(1)             File_Name  \n",
       "0         -4.976188      0.999939      0.000061      gossipcop-848731  \n",
       "1         -3.713171      0.999334      0.000666      gossipcop-944840  \n",
       "2         -4.097625      0.999663      0.000337  gossipcop-1267637959  \n",
       "3          0.517232      0.238087      0.761913      gossipcop-909119  \n",
       "4         -5.004924      0.999942      0.000058      gossipcop-866623  \n",
       "...             ...           ...           ...                   ...  \n",
       "3658       0.280135      0.301728      0.698272  gossipcop-6231788357  \n",
       "3659      -5.073880      0.999948      0.000052      gossipcop-896655  \n",
       "3660       0.738307      0.184808      0.815192      gossipcop-856760  \n",
       "3661      -5.085905      0.999947      0.000053      gossipcop-854426  \n",
       "3662      -4.499780      0.999843      0.000157  gossipcop-7744016686  \n",
       "\n",
       "[3663 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label of 0 is real, 1 is fake\n",
    "eval_results = pd.DataFrame({\"Article\": list(range(len(labels))),\n",
    "                             \"Source\": sources,\n",
    "                             \"Token_Length\": article_tokens,\n",
    "                             \"Predictions\": preds,\n",
    "                             \"Labels\": labels,\n",
    "                             \"Logit_real(0)\": [x[0] for x in logits],\n",
    "                             \"Logit_fake(1)\": [x[1] for x in logits],\n",
    "                             \"Prob_real(0)\": [x[0] for x in probs],\n",
    "                             \"Prob_real(1)\": [x[1] for x in probs],\n",
    "                             \"File_Name\": file_names})\n",
    "\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation data to csv file\n",
    "eval_results.to_csv(\"eval_data_\" + MODEL_FILE[12:-4] + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Overall Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Distilbert trained on politifact and gossipcop training data.',\n",
       " 'eval_notes': 'Evaluating both gossipcop and poltifact data',\n",
       " 'model': 'saved_model_epoch10_20201126_1415.tar',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 32,\n",
       " 'Date_evaluated': '25Nov2020',\n",
       " 'train_data': 'train_dataset_25Nov_gcpf_distilbert.pickle',\n",
       " 'val_data': 'eval_data_epoch10_20201126_1415.csv',\n",
       " 'eval_data': 'val_dataset_25Nov_gcpf_distilbert.pickle',\n",
       " 'accuracy': 0.8555828555828556,\n",
       " 'precision': 0.7588555858310627,\n",
       " 'recall': 0.6127612761276128,\n",
       " 'f1': 0.6780279975654291}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall metrics\n",
    "precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "    labels, preds, average=\"binary\")\n",
    "accuracy = sklearn.metrics.accuracy_score(labels, preds)\n",
    "\n",
    "metrics = {\"description\": DESCRIPTION,\n",
    "           \"eval_notes\": \"Evaluating both gossipcop and poltifact data\",\n",
    "           \"model\": MODEL_FILE,\n",
    "           \"epochs\": checkpoint[\"epoch\"],\n",
    "           \"batch_size\": EVAL_BATCH_SIZE,\n",
    "           \"Date_evaluated\": \"25Nov2020\",\n",
    "           \"train_data\": \"train_dataset_25Nov_gcpf_distilbert.pickle\",\n",
    "           \"val_data\": \"eval_data_\" + MODEL_FILE[12:-4] + \".csv\",\n",
    "           \"eval_data\": VAL_DATASET,\n",
    "           \"accuracy\": accuracy,\n",
    "           \"precision\": precision,\n",
    "           \"recall\": recall,\n",
    "           \"f1\": f1}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to JSON text file.\n",
    "with open(\"eval_metrics_\" + MODEL_FILE[12:-4] + \".json\", \"wt\") as jfile:\n",
    "    json.dump(metrics, jfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Evaluate on Gossipcop Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Distilbert trained on politifact and gossipcop training data.',\n",
       " 'eval_notes': 'Evaluating on gossipcop data only (model trained on both).',\n",
       " 'model': 'saved_model_epoch10_20201126_1415.tar',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 32,\n",
       " 'Date_evaluated': '25Nov2020',\n",
       " 'train_data': 'train_dataset_25Nov_gcpf_distilbert.pickle',\n",
       " 'val_data': 'eval_data_epoch10_20201126_1415.csv',\n",
       " 'eval_data': 'val_dataset_25Nov_gcpf_distilbert.pickle',\n",
       " 'accuracy': 0.8587634713556438,\n",
       " 'precision': 0.7489239598278336,\n",
       " 'recall': 0.6177514792899408,\n",
       " 'f1': 0.6770428015564202}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gossipcop evaluation\n",
    "gc_results = eval_results.query(\"Source == 'gossipcop'\")\n",
    "filtered_labels = gc_results.Labels\n",
    "filtered_preds = gc_results.Predictions\n",
    "precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "    filtered_labels, filtered_preds, average=\"binary\")\n",
    "accuracy = sklearn.metrics.accuracy_score(filtered_labels, filtered_preds)\n",
    "\n",
    "gc_metrics = {\"description\": DESCRIPTION,\n",
    "           \"eval_notes\": \"Evaluating on gossipcop data only (model trained on both).\",\n",
    "           \"model\": MODEL_FILE,\n",
    "           \"epochs\": checkpoint[\"epoch\"],\n",
    "           \"batch_size\": EVAL_BATCH_SIZE,\n",
    "           \"Date_evaluated\": \"25Nov2020\",\n",
    "           \"train_data\": \"train_dataset_25Nov_gcpf_distilbert.pickle\",\n",
    "           \"val_data\": \"eval_data_\" + MODEL_FILE[12:-4] + \".csv\",\n",
    "           \"eval_data\": VAL_DATASET,\n",
    "           \"accuracy\": accuracy,\n",
    "           \"precision\": precision,\n",
    "           \"recall\": recall,\n",
    "           \"f1\": f1}\n",
    "gc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to JSON text file.\n",
    "with open(\"eval_metrics_gc_\" + MODEL_FILE[12:-4] + \".json\", \"wt\") as jfile:\n",
    "    json.dump(gc_metrics, jfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Evaluate on Politifact Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Distilbert trained on politifact and gossipcop training data.',\n",
       " 'eval_notes': 'Evaluating on politifact data only (model trained on both).',\n",
       " 'model': 'saved_model_epoch10_20201126_1415.tar',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 32,\n",
       " 'Date_evaluated': '25Nov2020',\n",
       " 'train_data': 'train_dataset_25Nov_gcpf_distilbert.pickle',\n",
       " 'val_data': 'eval_data_epoch10_20201126_1415.csv',\n",
       " 'eval_data': 'val_dataset_25Nov_gcpf_distilbert.pickle',\n",
       " 'accuracy': 0.7737226277372263,\n",
       " 'precision': 0.9459459459459459,\n",
       " 'recall': 0.546875,\n",
       " 'f1': 0.6930693069306929}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Politifact Metrics\n",
    "pf_results = eval_results.query(\"Source == 'politifact'\")\n",
    "filtered_labels = pf_results.Labels\n",
    "filtered_preds = pf_results.Predictions\n",
    "precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "    filtered_labels, filtered_preds, average=\"binary\")\n",
    "accuracy = sklearn.metrics.accuracy_score(filtered_labels, filtered_preds)\n",
    "\n",
    "pf_metrics = {\"description\": DESCRIPTION,\n",
    "           \"eval_notes\": \"Evaluating on politifact data only (model trained on both).\",\n",
    "           \"model\": MODEL_FILE,\n",
    "           \"epochs\": checkpoint[\"epoch\"],\n",
    "           \"batch_size\": EVAL_BATCH_SIZE,\n",
    "           \"Date_evaluated\": \"25Nov2020\",\n",
    "           \"train_data\": \"train_dataset_25Nov_gcpf_distilbert.pickle\",\n",
    "           \"val_data\": \"eval_data_\" + MODEL_FILE[12:-4] + \".csv\",\n",
    "           \"eval_data\": VAL_DATASET,\n",
    "           \"accuracy\": accuracy,\n",
    "           \"precision\": precision,\n",
    "           \"recall\": recall,\n",
    "           \"f1\": f1}\n",
    "pf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to JSON text file.\n",
    "with open(\"eval_metrics_pf_\" + MODEL_FILE[12:-4] + \".json\", \"wt\") as jfile:\n",
    "    json.dump(pf_metrics, jfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Articles <= 512 Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Distilbert trained on politifact and gossipcop training data.',\n",
       " 'eval_notes': 'Evaluating on short articles only.',\n",
       " 'model': 'saved_model_epoch10_20201126_1415.tar',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 32,\n",
       " 'Date_evaluated': '25Nov2020',\n",
       " 'train_data': 'train_dataset_25Nov_gcpf_distilbert.pickle',\n",
       " 'val_data': 'eval_data_epoch10_20201126_1415.csv',\n",
       " 'eval_data': 'val_dataset_25Nov_gcpf_distilbert.pickle',\n",
       " 'accuracy': 0.8677130044843049,\n",
       " 'precision': 0.8092643051771117,\n",
       " 'recall': 0.6414686825053996,\n",
       " 'f1': 0.7156626506024095}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Short Articles\n",
    "short_results = eval_results.query(\"Token_Length <= 512\")\n",
    "filtered_labels = short_results.Labels\n",
    "filtered_preds = short_results.Predictions\n",
    "precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "    filtered_labels, filtered_preds, average=\"binary\")\n",
    "accuracy = sklearn.metrics.accuracy_score(filtered_labels, filtered_preds)\n",
    "\n",
    "short_metrics = {\"description\": DESCRIPTION,\n",
    "           \"eval_notes\": \"Evaluating on short articles only.\",\n",
    "           \"model\": MODEL_FILE,\n",
    "           \"epochs\": checkpoint[\"epoch\"],\n",
    "           \"batch_size\": EVAL_BATCH_SIZE,\n",
    "           \"Date_evaluated\": \"25Nov2020\",\n",
    "           \"train_data\": \"train_dataset_25Nov_gcpf_distilbert.pickle\",\n",
    "           \"val_data\": \"eval_data_\" + MODEL_FILE[12:-4] + \".csv\",\n",
    "           \"eval_data\": VAL_DATASET,\n",
    "           \"accuracy\": accuracy,\n",
    "           \"precision\": precision,\n",
    "           \"recall\": recall,\n",
    "           \"f1\": f1}\n",
    "short_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to JSON text file.\n",
    "with open(\"eval_metrics_short_\" + MODEL_FILE[12:-4] + \".json\", \"wt\") as jfile:\n",
    "    json.dump(short_metrics, jfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Articles > 512 Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Distilbert trained on politifact and gossipcop training data.',\n",
       " 'eval_notes': 'Evaluating on long articles only.',\n",
       " 'model': 'saved_model_epoch10_20201126_1415.tar',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 32,\n",
       " 'Date_evaluated': '25Nov2020',\n",
       " 'train_data': 'train_dataset_25Nov_gcpf_distilbert.pickle',\n",
       " 'val_data': 'eval_data_epoch10_20201126_1415.csv',\n",
       " 'eval_data': 'val_dataset_25Nov_gcpf_distilbert.pickle',\n",
       " 'accuracy': 0.8440659925492283,\n",
       " 'precision': 0.7084468664850136,\n",
       " 'recall': 0.5829596412556054,\n",
       " 'f1': 0.6396063960639606}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Long Articles\n",
    "long_results = eval_results.query(\"Token_Length > 512\")\n",
    "filtered_labels = long_results.Labels\n",
    "filtered_preds = long_results.Predictions\n",
    "precision, recall, f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "    filtered_labels, filtered_preds, average=\"binary\")\n",
    "accuracy = sklearn.metrics.accuracy_score(filtered_labels, filtered_preds)\n",
    "\n",
    "long_metrics = {\"description\": DESCRIPTION,\n",
    "           \"eval_notes\": \"Evaluating on long articles only.\",\n",
    "           \"model\": MODEL_FILE,\n",
    "           \"epochs\": checkpoint[\"epoch\"],\n",
    "           \"batch_size\": EVAL_BATCH_SIZE,\n",
    "           \"Date_evaluated\": \"25Nov2020\",\n",
    "           \"train_data\": \"train_dataset_25Nov_gcpf_distilbert.pickle\",\n",
    "           \"val_data\": \"eval_data_\" + MODEL_FILE[12:-4] + \".csv\",\n",
    "           \"eval_data\": VAL_DATASET,\n",
    "           \"accuracy\": accuracy,\n",
    "           \"precision\": precision,\n",
    "           \"recall\": recall,\n",
    "           \"f1\": f1}\n",
    "long_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to JSON text file.\n",
    "with open(\"eval_metrics_long_\" + MODEL_FILE[12:-4] + \".json\", \"wt\") as jfile:\n",
    "    json.dump(long_metrics, jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
